import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from datetime import datetime

def validar_dados(df):
    """Valida os dados conforme as premissas do projeto"""
    try:
        # Convertendo colunas de tempo para datetime
        df['retirada'] = pd.to_datetime(df['retirada'])
        df['inicio'] = pd.to_datetime(df['inicio'])
        df['fim'] = pd.to_datetime(df['fim'])
        
        # Aplicando filtros conforme premissas
        df = df[
            (df['tpatend'] >= 60) &  # MÃ­nimo 1 minuto
            (df['tpatend'] <= 1800) &  # MÃ¡ximo 30 minutos
            (df['tpesper'] <= 14400) &  # MÃ¡ximo 4 horas de espera
            (df['status'].isin(['ATENDIDO', 'TRANSFERIDA']))
        ]
        
        return df
    
    except Exception as e:
        st.error(f"Erro na validaÃ§Ã£o dos dados: {str(e)}")
        return None

def validar_colunas(df):
    """Valida e padroniza os nomes das colunas"""
    # Mapeamento de possÃ­veis nomes para nomes padronizados
    mapa_colunas = {
        # Status
        'status_descricao': 'status',
        'status descriÃ§Ã£o': 'status',
        'Status DescriÃ§Ã£o': 'status',
        'Status': 'status',
        'STATUS': 'status',
        
        # GuichÃª
        'guiche': 'guichÃª',
        'guichÃª': 'guichÃª',
        'GuichÃª': 'guichÃª',
        'Guiche': 'guichÃª',
        'GUICHE': 'guichÃª',
        
        # UsuÃ¡rio
        'usuario': 'usuÃ¡rio',
        'usuÃ¡rio': 'usuÃ¡rio',
        'UsuÃ¡rio': 'usuÃ¡rio',
        'Usuario': 'usuÃ¡rio',
        'USUARIO': 'usuÃ¡rio',
        
        # Datas e Tempos (jÃ¡ estÃ£o corretos)
        'retirada': 'retirada',
        'inicio': 'inicio',
        'fim': 'fim',
        'tpatend': 'tpatend',
        'tpesper': 'tpesper'
    }
    
    # Renomear colunas existentes
    for col_atual in df.columns:
        col_lower = col_atual.lower().strip()
        for key, value in mapa_colunas.items():
            if col_lower == key.lower():
                df = df.rename(columns={col_atual: value})
                break
    
    # Verificar colunas obrigatÃ³rias da base
    colunas_obrigatorias = [
        'status', 'guichÃª', 'usuÃ¡rio',
        'retirada', 'inicio', 'fim', 
        'tpatend', 'tpesper', 'prefixo'  # prefixo necessÃ¡rio para merge
    ]
    
    colunas_faltantes = [col for col in colunas_obrigatorias if col not in df.columns]
    
    if colunas_faltantes:
        st.error(f"âŒ Colunas nÃ£o encontradas: {', '.join(colunas_faltantes)}")
        st.write("Por favor, verifique se seu arquivo possui as seguintes colunas:")
        for col in colunas_obrigatorias:
            st.write(f"- {col}")
        raise ValueError("Estrutura do arquivo invÃ¡lida")
    
    return df

def carregar_dados_github():
    """Carrega dados do repositÃ³rio GitHub"""
    try:
        # ConfiguraÃ§Ã£o da API do GitHub
        owner = "RobsonFSVieira"
        repo = "dashboard_desempenho"
        branch = "main"
        path = "dados"
        
        # URLs da API do GitHub
        api_base = f"https://api.github.com/repos/{owner}/{repo}/contents/{path}"
        headers = {'Accept': 'application/vnd.github.v3.raw'}
        
        # Mapeamento de arquivos
        arquivos = {
            'base': 'base.xlsx',
            'codigo': 'codigo.xlsx',
            'medias': 'medias_atend.xlsx'
        }
        
        dados = {}
        
        for key, filename in arquivos.items():
            try:
                url = f"{api_base}/{filename}?ref={branch}"
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    content = BytesIO(response.content)
                    if key == 'medias':
                        dados[key] = pd.read_excel(content, sheet_name="DADOS")
                    else:
                        dados[key] = pd.read_excel(content)
                else:
                    st.warning(f"âš ï¸ Arquivo {filename} nÃ£o encontrado no GitHub (Status: {response.status_code})")
                    return None
            except Exception as e:
                st.warning(f"âš ï¸ Erro ao carregar {filename}: {str(e)}")
                return None
        
        if len(dados) == 3:
            st.success("âœ… Dados carregados com sucesso do GitHub!")
            return dados
        return None
    
    except Exception as e:
        st.warning(f"âš ï¸ Erro ao acessar GitHub: {str(e)}")
        return None

def carregar_dados():
    """Carrega e processa os arquivos necessÃ¡rios"""
    try:
        # Upload manual sempre disponÃ­vel na sidebar
        with st.sidebar.expander("ðŸ“ Upload Manual de Arquivos", expanded=False):
            arquivo_base = st.file_uploader(
                "Base de Dados (base.xlsx)", 
                type="xlsx",
                help="Arquivo com os dados brutos de atendimento"
            )
            
            arquivo_codigo = st.file_uploader(
                "CÃ³digos (codigo.xlsx)", 
                type="xlsx",
                help="Arquivo com os cÃ³digos de cliente e operaÃ§Ã£o"
            )
            
            arquivo_medias = st.file_uploader(
                "MÃ©dias (medias_atend.xlsx)", 
                type="xlsx",
                help="Arquivo com as mÃ©dias de atendimento"
            )

        # Se arquivos foram enviados manualmente, usar eles
        if all([arquivo_base, arquivo_codigo, arquivo_medias]):
            with st.spinner('Carregando dados enviados...'):
                try:
                    df_base = pd.read_excel(arquivo_base)
                    df_codigo = pd.read_excel(arquivo_codigo)
                    df_medias = pd.read_excel(arquivo_medias, sheet_name="DADOS")
                    
                    # ValidaÃ§Ãµes e processamento
                    df_base = validar_colunas(df_base)
                    df_base = validar_dados(df_base)
                    
                    if df_base is not None:
                        df_final = pd.merge(
                            df_base,
                            df_codigo[['prefixo', 'CLIENTE', 'OPERAÃ‡ÃƒO']],
                            on='prefixo',
                            how='left'
                        )
                        df_final['tempo_permanencia'] = df_final['tpatend'] + df_final['tpesper']
                        
                        return {
                            'base': df_final,
                            'medias': df_medias,
                            'codigo': df_codigo
                        }
                except Exception as e:
                    st.error(f"âŒ Erro ao processar arquivos enviados: {str(e)}")
                    return None

        # Se nÃ£o tem upload manual, tenta carregar do GitHub
        dados_github = carregar_dados_github()
        if dados_github:
            df_base = validar_colunas(dados_github['base'])
            df_base = validar_dados(df_base)
            
            if df_base is not None:
                df_final = pd.merge(
                    df_base,
                    dados_github['codigo'][['prefixo', 'CLIENTE', 'OPERAÃ‡ÃƒO']],
                    on='prefixo',
                    how='left'
                )
                df_final['tempo_permanencia'] = df_final['tpatend'] + df_final['tpesper']
                
                return {
                    'base': df_final,
                    'medias': dados_github['medias'],
                    'codigo': dados_github['codigo']
                }

        return None
            
    except Exception as e:
        st.error(f"âŒ Erro no carregamento: {str(e)}")
        return None